# è¾¹å¢™é²œé€ç³»ç»Ÿ - å®Œæ•´CI/CDéƒ¨ç½²æµç¨‹æŒ‡å—

## ğŸ“‹ ç›®å½•
- [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [CI/CDæµæ°´çº¿é…ç½®](#cicdæµæ°´çº¿é…ç½®)
- [éƒ¨ç½²ç¯å¢ƒé…ç½®](#éƒ¨ç½²ç¯å¢ƒé…ç½®)
- [è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹](#è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹)
- [ç›‘æ§ä¸è¿ç»´](#ç›‘æ§ä¸è¿ç»´)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### æŠ€æœ¯æ ˆ
- **åç«¯**: Spring Boot + MySQL + Redis
- **å‰ç«¯ç®¡ç†**: Vue.js + Element Plus
- **å°ç¨‹åº**: å¾®ä¿¡å°ç¨‹åºåŸç”Ÿå¼€å‘
- **å®¹å™¨åŒ–**: Docker + Docker Compose
- **CI/CD**: Jenkins Pipeline
- **åå‘ä»£ç†**: Nginx
- **ç›‘æ§**: æ—¥å¿—æ”¶é›† + å¥åº·æ£€æŸ¥

### éƒ¨ç½²æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å¼€å‘ç¯å¢ƒ      â”‚    â”‚   æµ‹è¯•ç¯å¢ƒ      â”‚    â”‚   ç”Ÿäº§ç¯å¢ƒ      â”‚
â”‚   (æœ¬åœ°)        â”‚    â”‚   (Staging)     â”‚    â”‚   (Production)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ä»£ç å¼€å‘      â”‚    â”‚ â€¢ è‡ªåŠ¨éƒ¨ç½²      â”‚    â”‚ â€¢ æ‰‹åŠ¨ç¡®è®¤éƒ¨ç½²  â”‚
â”‚ â€¢ å•å…ƒæµ‹è¯•      â”‚    â”‚ â€¢ é›†æˆæµ‹è¯•      â”‚    â”‚ â€¢ ç”Ÿäº§ç›‘æ§      â”‚
â”‚ â€¢ ä»£ç æäº¤      â”‚    â”‚ â€¢ åŠŸèƒ½éªŒè¯      â”‚    â”‚ â€¢ æ€§èƒ½ä¼˜åŒ–      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Jenkins       â”‚
                    â”‚   CI/CD æœåŠ¡å™¨  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### 1. æœåŠ¡å™¨ç¯å¢ƒè¦æ±‚

#### CI/CDæœåŠ¡å™¨ (Jenkins)
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 LTS æˆ– CentOS 8+
- **CPU**: 4æ ¸å¿ƒä»¥ä¸Š
- **å†…å­˜**: 8GBä»¥ä¸Š
- **å­˜å‚¨**: 100GBä»¥ä¸Š SSD
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

#### ç”Ÿäº§æœåŠ¡å™¨
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 LTS æˆ– CentOS 8+
- **CPU**: 8æ ¸å¿ƒä»¥ä¸Š
- **å†…å­˜**: 16GBä»¥ä¸Š
- **å­˜å‚¨**: 200GBä»¥ä¸Š SSD
- **ç½‘ç»œ**: é«˜å¸¦å®½ï¼Œä½å»¶è¿Ÿ

### 2. åŸºç¡€è½¯ä»¶å®‰è£…

#### åœ¨æ‰€æœ‰æœåŠ¡å™¨ä¸Šå®‰è£…Docker
```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# å®‰è£…Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

#### JenkinsæœåŠ¡å™¨é¢å¤–å®‰è£…
```bash
# å®‰è£…Jenkins
wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -
sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list'
sudo apt update
sudo apt install jenkins

# å®‰è£…Node.js (ç”¨äºå‰ç«¯æ„å»º)
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# å®‰è£…Maven (ç”¨äºåç«¯æ„å»º)
sudo apt install maven

# å®‰è£…Git
sudo apt install git
```

### 3. Jenkinsé…ç½®

#### å¿…éœ€æ’ä»¶å®‰è£…
```
- Pipeline
- Git
- Docker Pipeline
- SSH Agent
- Email Extension
- SonarQube Scanner
- OWASP Dependency Check
- Publish Test Results
- Code Coverage API
```

#### å…¨å±€å·¥å…·é…ç½®
1. **JDK**: OpenJDK 17
2. **Maven**: Apache Maven 3.8+
3. **Node.js**: Node.js 18+
4. **Docker**: Docker latest

#### å‡­æ®é…ç½®
```
- docker-registry-credentials: Dockeré•œåƒä»“åº“å‡­æ®
- deploy-ssh-key: éƒ¨ç½²æœåŠ¡å™¨SSHå¯†é’¥
- dingtalk-webhook: é’‰é’‰é€šçŸ¥Webhook
- sonarqube-token: SonarQubeè®¿é—®ä»¤ç‰Œ
```

## ğŸ”„ CI/CDæµæ°´çº¿é…ç½®

### 1. Jenkinsfileè¯¦è§£

æˆ‘ä»¬çš„Jenkinsæµæ°´çº¿åŒ…å«ä»¥ä¸‹é˜¶æ®µï¼š

#### é˜¶æ®µ1: ä»£ç æ£€å‡º (Checkout)
```groovy
stage('Checkout') {
    steps {
        git branch: "${GIT_BRANCH}", url: "${GIT_REPO}"
        script {
            env.BUILD_TIME = sh(returnStdout: true, script: 'date +"%Y-%m-%d %H:%M:%S"').trim()
            env.GIT_COMMIT_SHORT = sh(returnStdout: true, script: 'git rev-parse --short HEAD').trim()
        }
    }
}
```

#### é˜¶æ®µ2: åç«¯æ„å»º (Build Backend)
```groovy
stage('Build Backend') {
    steps {
        dir('backend') {
            sh 'mvn clean compile'
            sh 'mvn test'
            sh 'mvn package -DskipTests'
        }
    }
    post {
        always {
            publishTestResults testResultsPattern: 'backend/target/surefire-reports/*.xml'
            publishCoverage adapters: [jacocoAdapter('backend/target/site/jacoco/jacoco.xml')]
        }
    }
}
```

#### é˜¶æ®µ3: å‰ç«¯æ„å»º (Build Frontend)
```groovy
stage('Build Frontend') {
    steps {
        dir('admin-frontend') {
            sh 'npm install --registry=https://registry.npmmirror.com'
            sh 'npm run lint'
            sh 'npm run build'
        }
    }
}
```

#### é˜¶æ®µ4: ä»£ç è´¨é‡åˆ†æ
```groovy
stage('Code Quality Analysis') {
    parallel {
        stage('SonarQube Analysis') {
            steps {
                withSonarQubeEnv('SonarQube') {
                    dir('backend') {
                        sh 'mvn sonar:sonar'
                    }
                }
            }
        }
        stage('Security Scan') {
            steps {
                dependencyCheck additionalArguments: '--format XML --format HTML', odcInstallation: 'OWASP-DC'
                dependencyCheckPublisher pattern: '**/dependency-check-report.xml'
            }
        }
    }
}
```

#### é˜¶æ®µ5: Dockeré•œåƒæ„å»º
```groovy
stage('Build Docker Images') {
    steps {
        script {
            def backendImage = docker.build("${PROJECT_NAME}-backend:${BUILD_NUMBER}", "./backend")
            def frontendImage = docker.build("${PROJECT_NAME}-admin:${BUILD_NUMBER}", "./admin-frontend")
            
            docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                backendImage.push()
                backendImage.push('latest')
                frontendImage.push()
                frontendImage.push('latest')
            }
        }
    }
}
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

åœ¨Jenkinsä¸­é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
# é¡¹ç›®é…ç½®
PROJECT_NAME=biangqiang-fresh-delivery
DOCKER_REGISTRY=your-docker-registry.com

# Gité…ç½®
GIT_REPO=https://github.com/your-username/biangqiang-fresh-delivery.git
GIT_BRANCH=main

# éƒ¨ç½²é…ç½®
DEPLOY_SERVER=your-deploy-server.com
DEPLOY_USER=deploy

# é€šçŸ¥é…ç½®
DINGTALK_WEBHOOK=https://oapi.dingtalk.com/robot/send?access_token=xxx
EMAIL_RECIPIENTS=admin@biangqiang.com
```

## ğŸš€ éƒ¨ç½²ç¯å¢ƒé…ç½®

### 1. æµ‹è¯•ç¯å¢ƒ (Staging)

#### ç›®å½•ç»“æ„
```
/opt/fresh-delivery/staging/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”œâ”€â”€ admin.conf
â”‚   â””â”€â”€ ssl/
â”œâ”€â”€ mysql/
â”‚   â”œâ”€â”€ conf/
â”‚   â””â”€â”€ init/
â””â”€â”€ redis/
    â””â”€â”€ redis.conf
```

#### ç¯å¢ƒå˜é‡æ–‡ä»¶ (.env)
```bash
# æ•°æ®åº“é…ç½®
MYSQL_ROOT_PASSWORD=TestRoot2024!@#
MYSQL_DATABASE=fresh_delivery_test
MYSQL_USERNAME=fresh_test
MYSQL_PASSWORD=FreshTest2024!@#

# Redisé…ç½®
REDIS_PASSWORD=RedisTest2024!@#

# åº”ç”¨é…ç½®
SPRING_PROFILES_ACTIVE=staging
JWT_SECRET=fresh-delivery-jwt-secret-test-2024
FILE_DOMAIN=https://staging.biangqiang.com

# å¾®ä¿¡é…ç½®
WECHAT_APPID=your_test_wechat_appid
WECHAT_SECRET=your_test_wechat_secret

# JVMé…ç½®
JAVA_OPTS=-Xmx1g -Xms512m -XX:+UseG1GC
```

### 2. ç”Ÿäº§ç¯å¢ƒ (Production)

#### ç›®å½•ç»“æ„
```
/opt/fresh-delivery/production/
â”œâ”€â”€ docker-compose.prod.yml
â”œâ”€â”€ .env.prod
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”œâ”€â”€ admin.conf
â”‚   â””â”€â”€ ssl/
â”œâ”€â”€ mysql/
â”‚   â”œâ”€â”€ conf/
â”‚   â””â”€â”€ init/
â”œâ”€â”€ redis/
â”‚   â””â”€â”€ redis.conf
â”œâ”€â”€ backups/
â””â”€â”€ logs/
```

#### ç”Ÿäº§ç¯å¢ƒå˜é‡æ–‡ä»¶ (.env.prod)
```bash
# æ•°æ®åº“é…ç½®
MYSQL_ROOT_PASSWORD=FreshDelivery2024!@#
MYSQL_DATABASE=fresh_delivery
MYSQL_USERNAME=fresh_user
MYSQL_PASSWORD=FreshUser2024!@#

# Redisé…ç½®
REDIS_PASSWORD=Redis2024!@#

# åº”ç”¨é…ç½®
SPRING_PROFILES_ACTIVE=production
JWT_SECRET=fresh-delivery-jwt-secret-prod-2024
FILE_DOMAIN=https://api.biangqiang.com

# å¾®ä¿¡é…ç½®
WECHAT_APPID=your_prod_wechat_appid
WECHAT_SECRET=your_prod_wechat_secret

# JVMé…ç½®
JAVA_OPTS=-Xmx2g -Xms1g -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError
```

### 3. Nginxé…ç½®ä¼˜åŒ–

#### ç”Ÿäº§ç¯å¢ƒNginxé…ç½®
```nginx
# /opt/fresh-delivery/production/nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    
    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;
    
    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend {
        server backend:8080;
        keepalive 32;
    }
    
    upstream admin {
        server admin-frontend:80;
        keepalive 32;
    }
    
    # HTTPSé‡å®šå‘
    server {
        listen 80;
        server_name _;
        return 301 https://$server_name$request_uri;
    }
    
    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 443 ssl http2;
        server_name _;
        
        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/server.crt;
        ssl_certificate_key /etc/nginx/ssl/server.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        
        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
        
        # APIä»£ç†
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
        # æ–‡ä»¶ä¸Šä¼ ä»£ç†
        location /uploads/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # å¤§æ–‡ä»¶ä¸Šä¼ 
            client_max_body_size 100M;
        }
        
        # ç®¡ç†åå°
        location / {
            proxy_pass http://admin;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # é™æ€æ–‡ä»¶ç¼“å­˜
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            proxy_pass http://admin;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

## ğŸ”„ è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹

### 1. éƒ¨ç½²è„šæœ¬å¢å¼º

åˆ›å»ºå¢å¼ºç‰ˆéƒ¨ç½²è„šæœ¬ `deploy-enhanced.sh`ï¼š

```bash
#!/bin/bash

# è¾¹å¢™é²œé€ç³»ç»Ÿå¢å¼ºç‰ˆéƒ¨ç½²è„šæœ¬
# æ”¯æŒå¤šç¯å¢ƒã€å¥åº·æ£€æŸ¥ã€å›æ»šç­‰åŠŸèƒ½

set -e

# é…ç½®
PROJECT_NAME="fresh-delivery"
ENVIRONMENT=${1:-staging}  # staging æˆ– production
ACTION=${2:-deploy}        # deploy, rollback, status

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# ç¯å¢ƒé…ç½®
if [ "$ENVIRONMENT" = "production" ]; then
    COMPOSE_FILE="docker-compose.prod.yml"
    ENV_FILE=".env.prod"
    DEPLOY_DIR="/opt/fresh-delivery/production"
else
    COMPOSE_FILE="docker-compose.yml"
    ENV_FILE=".env"
    DEPLOY_DIR="/opt/fresh-delivery/staging"
fi

# å¥åº·æ£€æŸ¥
health_check() {
    local service=$1
    local max_attempts=30
    local attempt=1
    
    log_info "æ£€æŸ¥ $service æœåŠ¡å¥åº·çŠ¶æ€..."
    
    while [ $attempt -le $max_attempts ]; do
        if docker-compose -f "$DEPLOY_DIR/$COMPOSE_FILE" ps | grep -q "$service.*healthy\|$service.*Up"; then
            log_success "$service æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            return 0
        fi
        
        log_info "ç­‰å¾… $service æœåŠ¡å¯åŠ¨... ($attempt/$max_attempts)"
        sleep 10
        ((attempt++))
    done
    
    log_error "$service æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
    return 1
}

# éƒ¨ç½²å‡½æ•°
deploy() {
    log_info "å¼€å§‹éƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒ..."
    
    # åˆ›å»ºéƒ¨ç½²ç›®å½•
    mkdir -p "$DEPLOY_DIR"
    cd "$DEPLOY_DIR"
    
    # å¤‡ä»½å½“å‰ç‰ˆæœ¬
    if [ -f "$COMPOSE_FILE" ]; then
        log_info "å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
        cp "$COMPOSE_FILE" "$COMPOSE_FILE.backup.$(date +%Y%m%d_%H%M%S)"
    fi
    
    # æ‹‰å–æœ€æ–°é•œåƒ
    log_info "æ‹‰å–æœ€æ–°Dockeré•œåƒ..."
    docker-compose -f "$COMPOSE_FILE" pull
    
    # åœæ­¢æ—§æœåŠ¡
    log_info "åœæ­¢æ—§æœåŠ¡..."
    docker-compose -f "$COMPOSE_FILE" down
    
    # å¯åŠ¨æ–°æœåŠ¡
    log_info "å¯åŠ¨æ–°æœåŠ¡..."
    docker-compose -f "$COMPOSE_FILE" up -d
    
    # å¥åº·æ£€æŸ¥
    health_check "mysql" && \
    health_check "redis" && \
    health_check "backend" && \
    health_check "admin-frontend"
    
    if [ $? -eq 0 ]; then
        log_success "$ENVIRONMENT ç¯å¢ƒéƒ¨ç½²æˆåŠŸï¼"
        
        # æ¸…ç†æ—§é•œåƒ
        log_info "æ¸…ç†æ—§é•œåƒ..."
        docker system prune -f
        
        # å‘é€é€šçŸ¥
        send_notification "success" "$ENVIRONMENT ç¯å¢ƒéƒ¨ç½²æˆåŠŸ"
    else
        log_error "$ENVIRONMENT ç¯å¢ƒéƒ¨ç½²å¤±è´¥ï¼"
        
        # è‡ªåŠ¨å›æ»š
        log_info "å¼€å§‹è‡ªåŠ¨å›æ»š..."
        rollback
        
        # å‘é€é€šçŸ¥
        send_notification "failure" "$ENVIRONMENT ç¯å¢ƒéƒ¨ç½²å¤±è´¥ï¼Œå·²è‡ªåŠ¨å›æ»š"
        exit 1
    fi
}

# å›æ»šå‡½æ•°
rollback() {
    log_info "å¼€å§‹å›æ»š $ENVIRONMENT ç¯å¢ƒ..."
    
    cd "$DEPLOY_DIR"
    
    # æŸ¥æ‰¾æœ€æ–°å¤‡ä»½
    BACKUP_FILE=$(ls -t "$COMPOSE_FILE.backup."* 2>/dev/null | head -n1)
    
    if [ -n "$BACKUP_FILE" ]; then
        log_info "ä½¿ç”¨å¤‡ä»½æ–‡ä»¶: $BACKUP_FILE"
        
        # åœæ­¢å½“å‰æœåŠ¡
        docker-compose -f "$COMPOSE_FILE" down
        
        # æ¢å¤å¤‡ä»½
        cp "$BACKUP_FILE" "$COMPOSE_FILE"
        
        # å¯åŠ¨æœåŠ¡
        docker-compose -f "$COMPOSE_FILE" up -d
        
        # å¥åº·æ£€æŸ¥
        if health_check "backend"; then
            log_success "å›æ»šæˆåŠŸï¼"
        else
            log_error "å›æ»šå¤±è´¥ï¼"
            exit 1
        fi
    else
        log_error "æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶ï¼Œæ— æ³•å›æ»šï¼"
        exit 1
    fi
}

# çŠ¶æ€æ£€æŸ¥
status() {
    log_info "æ£€æŸ¥ $ENVIRONMENT ç¯å¢ƒçŠ¶æ€..."
    
    cd "$DEPLOY_DIR"
    docker-compose -f "$COMPOSE_FILE" ps
    
    # æ£€æŸ¥å„æœåŠ¡çŠ¶æ€
    services=("mysql" "redis" "backend" "admin-frontend")
    
    for service in "${services[@]}"; do
        if docker-compose -f "$COMPOSE_FILE" ps | grep -q "$service.*Up"; then
            log_success "$service æœåŠ¡è¿è¡Œæ­£å¸¸"
        else
            log_error "$service æœåŠ¡å¼‚å¸¸"
        fi
    done
}

# å‘é€é€šçŸ¥
send_notification() {
    local status=$1
    local message=$2
    local emoji
    
    if [ "$status" = "success" ]; then
        emoji="âœ…"
    else
        emoji="âŒ"
    fi
    
    # è¿™é‡Œå¯ä»¥é›†æˆé’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ç­‰é€šçŸ¥
    log_info "$emoji $message"
}

# ä¸»å‡½æ•°
main() {
    case "$ACTION" in
        "deploy")
            deploy
            ;;
        "rollback")
            rollback
            ;;
        "status")
            status
            ;;
        *)
            echo "ä½¿ç”¨æ–¹æ³•: $0 [staging|production] [deploy|rollback|status]"
            exit 1
            ;;
    esac
}

# æ‰§è¡Œä¸»å‡½æ•°
main
```

### 2. è‡ªåŠ¨åŒ–éƒ¨ç½²è§¦å‘

#### Git Hooksé…ç½®

åœ¨Gitä»“åº“ä¸­é…ç½®post-receive hookï¼š

```bash
#!/bin/bash
# post-receive hook

while read oldrev newrev refname; do
    branch=$(git rev-parse --symbolic --abbrev-ref $refname)
    
    if [ "$branch" = "main" ]; then
        echo "è§¦å‘ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²..."
        curl -X POST "http://jenkins-server:8080/job/fresh-delivery-production/build" \
             --user "jenkins-user:jenkins-token"
    elif [ "$branch" = "develop" ]; then
        echo "è§¦å‘æµ‹è¯•ç¯å¢ƒéƒ¨ç½²..."
        curl -X POST "http://jenkins-server:8080/job/fresh-delivery-staging/build" \
             --user "jenkins-user:jenkins-token"
    fi
done
```

#### Webhooké…ç½®

åœ¨GitHub/GitLabä¸­é…ç½®Webhookï¼ŒæŒ‡å‘Jenkinsï¼š

```
URL: http://jenkins-server:8080/github-webhook/
Content type: application/json
Events: Push events, Pull request events
```

## ğŸ“Š ç›‘æ§ä¸è¿ç»´

### 1. æ—¥å¿—æ”¶é›†é…ç½®

#### Dockeræ—¥å¿—é…ç½®
```yaml
# docker-compose.prod.yml ä¸­çš„æ—¥å¿—é…ç½®
logging:
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "5"
```

#### é›†ä¸­æ—¥å¿—æ”¶é›†
```bash
# å®‰è£…ELK Stack (å¯é€‰)
docker run -d --name elasticsearch \
  -p 9200:9200 -p 9300:9300 \
  -e "discovery.type=single-node" \
  elasticsearch:7.14.0

docker run -d --name kibana \
  -p 5601:5601 \
  --link elasticsearch:elasticsearch \
  kibana:7.14.0

docker run -d --name logstash \
  -p 5044:5044 \
  --link elasticsearch:elasticsearch \
  logstash:7.14.0
```

### 2. å¥åº·æ£€æŸ¥å’Œç›‘æ§

#### åº”ç”¨å¥åº·æ£€æŸ¥ç«¯ç‚¹

åœ¨Spring Bootåº”ç”¨ä¸­æ·»åŠ å¥åº·æ£€æŸ¥ï¼š

```java
@RestController
@RequestMapping("/api")
public class HealthController {
    
    @Autowired
    private DataSource dataSource;
    
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @GetMapping("/health")
    public ResponseEntity<Map<String, Object>> health() {
        Map<String, Object> health = new HashMap<>();
        
        try {
            // æ£€æŸ¥æ•°æ®åº“è¿æ¥
            dataSource.getConnection().close();
            health.put("database", "UP");
        } catch (Exception e) {
            health.put("database", "DOWN");
            health.put("database_error", e.getMessage());
        }
        
        try {
            // æ£€æŸ¥Redisè¿æ¥
            redisTemplate.opsForValue().get("health_check");
            health.put("redis", "UP");
        } catch (Exception e) {
            health.put("redis", "DOWN");
            health.put("redis_error", e.getMessage());
        }
        
        health.put("status", "UP");
        health.put("timestamp", System.currentTimeMillis());
        
        return ResponseEntity.ok(health);
    }
}
```

#### ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

MONITOR_URL="https://your-domain.com/api/health"
ALERT_EMAIL="admin@biangqiang.com"
LOG_FILE="/var/log/fresh-delivery-monitor.log"

check_service() {
    local response=$(curl -s -o /dev/null -w "%{http_code}" "$MONITOR_URL")
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    if [ "$response" = "200" ]; then
        echo "[$timestamp] æœåŠ¡æ­£å¸¸ - HTTP $response" >> "$LOG_FILE"
        return 0
    else
        echo "[$timestamp] æœåŠ¡å¼‚å¸¸ - HTTP $response" >> "$LOG_FILE"
        
        # å‘é€å‘Šè­¦é‚®ä»¶
        echo "è¾¹å¢™é²œé€ç³»ç»ŸæœåŠ¡å¼‚å¸¸ï¼ŒHTTPçŠ¶æ€ç : $response" | \
        mail -s "[å‘Šè­¦] è¾¹å¢™é²œé€ç³»ç»ŸæœåŠ¡å¼‚å¸¸" "$ALERT_EMAIL"
        
        return 1
    fi
}

# æ‰§è¡Œæ£€æŸ¥
check_service
```

#### Crontabé…ç½®
```bash
# æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æœåŠ¡çŠ¶æ€
* * * * * /opt/fresh-delivery/scripts/monitor.sh

# æ¯å¤©å‡Œæ™¨2ç‚¹å¤‡ä»½æ•°æ®åº“
0 2 * * * /opt/fresh-delivery/scripts/backup.sh

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹æ¸…ç†æ—§æ—¥å¿—
0 3 * * 0 /opt/fresh-delivery/scripts/cleanup.sh
```

### 3. æ€§èƒ½ç›‘æ§

#### ç³»ç»Ÿèµ„æºç›‘æ§
```bash
#!/bin/bash
# performance-monitor.sh

# CPUä½¿ç”¨ç‡
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')

# å†…å­˜ä½¿ç”¨ç‡
MEM_USAGE=$(free | grep Mem | awk '{printf("%.2f", $3/$2 * 100.0)}')

# ç£ç›˜ä½¿ç”¨ç‡
DISK_USAGE=$(df -h / | awk 'NR==2{printf "%s", $5}')

# Dockerå®¹å™¨çŠ¶æ€
CONTAINER_COUNT=$(docker ps | wc -l)

echo "ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š - $(date)"
echo "CPUä½¿ç”¨ç‡: ${CPU_USAGE}%"
echo "å†…å­˜ä½¿ç”¨ç‡: ${MEM_USAGE}%"
echo "ç£ç›˜ä½¿ç”¨ç‡: ${DISK_USAGE}"
echo "è¿è¡Œå®¹å™¨æ•°: $((CONTAINER_COUNT-1))"

# å¦‚æœèµ„æºä½¿ç”¨ç‡è¿‡é«˜ï¼Œå‘é€å‘Šè­¦
if (( $(echo "$CPU_USAGE > 80" | bc -l) )) || (( $(echo "$MEM_USAGE > 80" | bc -l) )); then
    echo "èµ„æºä½¿ç”¨ç‡è¿‡é«˜ï¼Œå‘é€å‘Šè­¦..." | mail -s "[å‘Šè­¦] ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡è¿‡é«˜" admin@biangqiang.com
fi
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### 1. å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1: å®¹å™¨å¯åŠ¨å¤±è´¥
```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs [service-name]

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker-compose ps

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker-compose exec [service-name] /bin/bash
```

#### é—®é¢˜2: æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥æ•°æ®åº“å®¹å™¨çŠ¶æ€
docker-compose exec mysql mysql -u root -p -e "SHOW DATABASES;"

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker network ls
docker network inspect [network-name]
```

#### é—®é¢˜3: å†…å­˜ä¸è¶³
```bash
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨æƒ…å†µ
docker stats

# æ¸…ç†æ— ç”¨é•œåƒå’Œå®¹å™¨
docker system prune -a

# è°ƒæ•´JVMå†…å­˜å‚æ•°
export JAVA_OPTS="-Xmx1g -Xms512m"
```

### 2. æ•…éšœæ¢å¤æµç¨‹

#### è‡ªåŠ¨æ•…éšœæ¢å¤è„šæœ¬
```bash
#!/bin/bash
# auto-recovery.sh

SERVICE_URL="https://your-domain.com/api/health"
MAX_RETRIES=3
RETRY_COUNT=0

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
    if curl -f "$SERVICE_URL" > /dev/null 2>&1; then
        echo "æœåŠ¡æ­£å¸¸"
        exit 0
    else
        echo "æœåŠ¡å¼‚å¸¸ï¼Œå°è¯•é‡å¯... (ç¬¬ $((RETRY_COUNT+1)) æ¬¡)"
        
        # é‡å¯æœåŠ¡
        cd /opt/fresh-delivery/production
        docker-compose restart backend
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        sleep 30
        
        ((RETRY_COUNT++))
    fi
done

echo "è‡ªåŠ¨æ¢å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥"
exit 1
```

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. ä»£ç è´¨é‡ä¿è¯

#### Gitå·¥ä½œæµ
```
main (ç”Ÿäº§åˆ†æ”¯)
â”œâ”€â”€ release/v1.0 (å‘å¸ƒåˆ†æ”¯)
â”œâ”€â”€ develop (å¼€å‘åˆ†æ”¯)
â”‚   â”œâ”€â”€ feature/user-management
â”‚   â”œâ”€â”€ feature/order-system
â”‚   â””â”€â”€ feature/ai-chat
â””â”€â”€ hotfix/critical-bug (ç´§æ€¥ä¿®å¤)
```

#### ä»£ç å®¡æŸ¥æ¸…å•
- [ ] ä»£ç ç¬¦åˆå›¢é˜Ÿç¼–ç è§„èŒƒ
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] æ²¡æœ‰ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æ—¥å¿—è®°å½•é€‚å½“
- [ ] æ€§èƒ½å½±å“è¯„ä¼°
- [ ] å®‰å…¨æ¼æ´æ£€æŸ¥

### 2. éƒ¨ç½²å®‰å…¨

#### æ•æ„Ÿä¿¡æ¯ç®¡ç†
```bash
# ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯
export MYSQL_PASSWORD=$(cat /etc/secrets/mysql_password)
export JWT_SECRET=$(cat /etc/secrets/jwt_secret)

# æˆ–ä½¿ç”¨Docker secrets
docker secret create mysql_password /path/to/mysql_password.txt
```

#### ç½‘ç»œå®‰å…¨
```yaml
# docker-compose.yml ç½‘ç»œé…ç½®
networks:
  fresh-delivery-network:
    driver: bridge
    internal: true  # å†…éƒ¨ç½‘ç»œï¼Œä¸å…è®¸å¤–éƒ¨è®¿é—®
  
  public-network:
    driver: bridge
```

### 3. æ€§èƒ½ä¼˜åŒ–

#### æ•°æ®åº“ä¼˜åŒ–
```sql
-- æ·»åŠ ç´¢å¼•
CREATE INDEX idx_user_phone ON users(phone);
CREATE INDEX idx_order_status ON orders(status, created_at);
CREATE INDEX idx_product_category ON products(category_id, status);

-- åˆ†åŒºè¡¨ï¼ˆå¤§æ•°æ®é‡æ—¶ï¼‰
CREATE TABLE order_logs (
    id BIGINT AUTO_INCREMENT,
    order_id BIGINT,
    action VARCHAR(50),
    created_at TIMESTAMP
) PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026)
);
```

#### ç¼“å­˜ç­–ç•¥
```java
@Service
public class ProductService {
    
    @Cacheable(value = "products", key = "#categoryId")
    public List<Product> getProductsByCategory(Long categoryId) {
        return productRepository.findByCategoryId(categoryId);
    }
    
    @CacheEvict(value = "products", allEntries = true)
    public void clearProductCache() {
        // æ¸…é™¤æ‰€æœ‰äº§å“ç¼“å­˜
    }
}
```

### 4. ç›‘æ§å‘Šè­¦

#### å…³é”®æŒ‡æ ‡ç›‘æ§
- **ç³»ç»ŸæŒ‡æ ‡**: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ
- **åº”ç”¨æŒ‡æ ‡**: å“åº”æ—¶é—´ã€é”™è¯¯ç‡ã€ååé‡
- **ä¸šåŠ¡æŒ‡æ ‡**: è®¢å•é‡ã€ç”¨æˆ·æ´»è·ƒåº¦ã€æ”¯ä»˜æˆåŠŸç‡

#### å‘Šè­¦è§„åˆ™
```yaml
# å‘Šè­¦è§„åˆ™ç¤ºä¾‹
alerts:
  - name: high_cpu_usage
    condition: cpu_usage > 80%
    duration: 5m
    action: send_email
    
  - name: high_error_rate
    condition: error_rate > 5%
    duration: 2m
    action: send_sms
    
  - name: database_connection_failed
    condition: db_connection_failed
    duration: 1m
    action: auto_restart
```

## ğŸ“ è”ç³»æ”¯æŒ

å¦‚æœåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·è”ç³»ï¼š

- **æŠ€æœ¯æ”¯æŒ**: tech-support@biangqiang.com
- **è¿ç»´å›¢é˜Ÿ**: ops@biangqiang.com
- **ç´§æ€¥è”ç³»**: +86-xxx-xxxx-xxxx

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ç»´æŠ¤å›¢é˜Ÿ**: è¾¹å¢™é²œé€æŠ€æœ¯å›¢é˜Ÿ